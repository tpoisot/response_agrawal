% Don't be afraid of Open Access
% List of authors to be determined
% ...

In a recent Letter, @agrawal raises four points for which scientists should
be skeptical of the Open Access (OA) movement, two of which we think are
particularly mis-leading. First, that the impact factor of OA journals
is not higher than the impact factor of non-OA journals. Second, that it
is tempting to use the journal as a surrogate for the quality of a paper,
and less prestigious OA journals run a risk of seeing good papers viewed less
favorably. We do not think that any of these points are valid arguments against
open access.

First, the distinction beween OA and non OA journals is a clear false
dichotomy. OA is a mode of diffusion of scientific literature in which the
authors, or its home institution, buys back the rights of an article to the
publisher, so that the article is free to access. Although some journals apply
an OA licences to their entire content, an increasing number of publishers
are adopting *per* article OA options. Even though, the notion that pure-OA
journals have a lower impact is challenged by some. James Pringle of Thomson
ISI (i) recognizes that the relevance of journals when talking about OA is
dubious and (ii) "prospective authors should not fear publishing in these
journals" [http://www.nature.com/nature/focus/accessdebate/19.html]. In
addition, there are numerous studies showing a clear *Open Access citation
advantage* [http://www.istl.org/10-winter/article2.html].

Second, the fact that OA journals carry less prestige is not a problem with
the OA movement. Measures of journal impact are known to be extremely biased
by a few papers concentrating a few citations, and cannot possibly be used to
estimate the quality of a paper, let alone its *likely impact*. Simply put,
the impact factor of a journal is not the expected number of citations a single
paper will receive. If rigor is important to us, then it is unacceptable to
think that a paper is bad because it was published in a less respectable
journal, or that a paper is good because it was published in a highly
selective journal; the same paper is just as good whether published in *PLoS
One* or *Nature*. This point strikes us as a demonstration that the metrics
used for evaluations are biased. The recent years say the development of
*article-level* metrics, which are able to measure the impact of an article
regardless of the journal it appeared in. We think that rather than pushing
against the OA model, we should have a discussion about how these measures
can be used in the evaluation of scientists.

@agrawal concludes his paper on the need to find *an alternative model of
publishing that suits the primary goals of scientists*. On that, we could not
agree more. However, what that *primary goal* is seems open to debate. We
would like to make the point that, particularly in ecology and environmental
sciences, the primary goal of research should be to produce fundamental insights
that can be mobilized to solve large scale problems. Making information flow
freely between scientists, policy-makers, and stakeholders is paramount to
this effort. What does not strikes us as a *primary* goal, is the maximization
of self-aggrandizing, not to mention arbitrary, measures of impact.
